{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wildlife Camera Trap Classification with Azure Custom Vision\n",
    "*A Microsoft AI Services Tutorial for Ecological Research*\n",
    "\n",
    "## What This Demonstrates\n",
    "\n",
    "**Microsoft Custom Vision** for automated wildlife monitoring research. We'll show how to:\n",
    "- Set up an Azure Custom Vision project \n",
    "- Train a model with minimal wildlife data\n",
    "- Use the prediction API for batch processing\n",
    "- Export results for research analysis\n",
    "\n",
    "**Why Custom Vision for Research:**\n",
    "- **No ML expertise required** - visual training interface\n",
    "- **Small data friendly** - works with as few as 5 images per category  \n",
    "- **Research-ready APIs** - confidence scores and batch processing\n",
    "- **Scalable** - handles thousands of images via REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Create Azure Custom Vision Resource\n",
    "\n",
    "### Step 1: Azure Portal Setup\n",
    "**In Azure Portal:**\n",
    "1. Go to **Create a resource** â†’ **AI + Machine Learning** â†’ **Custom Vision**\n",
    "2. Create **Training resource** (F0 free tier available)\n",
    "3. Create **Prediction resource** (F0 free tier available)  \n",
    "4. Note down: **Keys**, **Endpoints**, and **Resource IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install azure-cognitiveservices-vision-customvision\n",
    "!pip install azure-cognitiveservices-vision-computervision  \n",
    "!pip install pillow matplotlib pandas requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import ImageFileCreateBatch, ImageFileCreateEntry\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Custom Vision Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure Custom Vision credentials (replace with your actual values)\n",
    "ENDPOINT = \"https://your-resource.cognitiveservices.azure.com/\"\n",
    "TRAINING_KEY = \"your_training_key_here\"\n",
    "PREDICTION_KEY = \"your_prediction_key_here\" \n",
    "PREDICTION_RESOURCE_ID = \"/subscriptions/your-sub-id/resourceGroups/your-rg/providers/Microsoft.CognitiveServices/accounts/your-prediction-resource\"\n",
    "\n",
    "# Initialize clients\n",
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": TRAINING_KEY})\n",
    "trainer = CustomVisionTrainingClient(ENDPOINT, training_credentials)\n",
    "\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": PREDICTION_KEY})\n",
    "predictor = CustomVisionPredictionClient(ENDPOINT, prediction_credentials)\n",
    "\n",
    "print(\"âœ… Custom Vision clients initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Setup: Create & Train Wildlife Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wildlife_project():\n",
    "    \"\"\"Create a new Custom Vision project for wildlife classification\"\"\"\n",
    "    \n",
    "    project_name = \"Wildlife Camera Trap Classifier\"\n",
    "    description = \"Classify animals from camera trap images for ecological research\"\n",
    "    \n",
    "    print(f\"Creating project: {project_name}\")\n",
    "    project = trainer.create_project(project_name, description=description)\n",
    "    \n",
    "    print(f\"âœ… Project created with ID: {project.id}\")\n",
    "    return project\n",
    "\n",
    "def create_wildlife_tags(project_id):\n",
    "    \"\"\"Create classification tags for common wildlife species\"\"\"\n",
    "    \n",
    "    # Common camera trap categories for quick demo\n",
    "    categories = [\n",
    "        \"deer\", \"fox\", \"bear\", \"raccoon\", \"coyote\", \n",
    "        \"rabbit\", \"squirrel\", \"bird\", \"empty\", \"human\"\n",
    "    ]\n",
    "    \n",
    "    tags = {}\n",
    "    for category in categories:\n",
    "        tag = trainer.create_tag(project_id, category)\n",
    "        tags[category] = tag\n",
    "        print(f\"Created tag: {category}\")\n",
    "    \n",
    "    return tags\n",
    "\n",
    "# Create project and tags\n",
    "project = create_wildlife_project()\n",
    "tags = create_wildlife_tags(project.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A: Quick Demo with Computer Vision\n",
    "\n",
    "**For immediate demonstration (no training data required):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_with_computer_vision():\n",
    "    \"\"\"\n",
    "    Use Azure Computer Vision for immediate wildlife detection demo\n",
    "    Demonstrates the API workflow without needing trained Custom Vision model\n",
    "    \"\"\"\n",
    "    from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "    from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "    \n",
    "    # Computer Vision credentials (same endpoint, different key)\n",
    "    CV_KEY = \"your_computer_vision_key\"\n",
    "    cv_client = ComputerVisionClient(ENDPOINT, ApiKeyCredentials(CV_KEY))\n",
    "    \n",
    "    def analyze_wildlife_image(image_url):\n",
    "        \"\"\"Analyze image for animals using Computer Vision\"\"\"\n",
    "        \n",
    "        # Analyze image for objects and animals\n",
    "        analysis = cv_client.analyze_image(\n",
    "            image_url, \n",
    "            visual_features=[VisualFeatureTypes.objects, VisualFeatureTypes.tags, VisualFeatureTypes.description]\n",
    "        )\n",
    "        \n",
    "        # Extract animal-related detections\n",
    "        wildlife_detections = []\n",
    "        \n",
    "        # Check objects for animals\n",
    "        for obj in analysis.objects:\n",
    "            if any(animal in obj.object_property.lower() for animal in ['animal', 'dog', 'cat', 'bird', 'deer', 'bear']):\n",
    "                wildlife_detections.append({\n",
    "                    'type': 'object',\n",
    "                    'name': obj.object_property,\n",
    "                    'confidence': obj.confidence,\n",
    "                    'bbox': [obj.rectangle.x, obj.rectangle.y, obj.rectangle.w, obj.rectangle.h]\n",
    "                })\n",
    "        \n",
    "        # Check tags for animal keywords\n",
    "        animal_tags = []\n",
    "        animal_keywords = ['deer', 'fox', 'bear', 'raccoon', 'bird', 'cat', 'dog', 'wildlife', 'animal']\n",
    "        \n",
    "        for tag in analysis.tags:\n",
    "            if any(keyword in tag.name.lower() for keyword in animal_keywords):\n",
    "                animal_tags.append({\n",
    "                    'name': tag.name,\n",
    "                    'confidence': tag.confidence\n",
    "                })\n",
    "        \n",
    "        return {\n",
    "            'description': analysis.description.captions[0].text if analysis.description.captions else \"No description\",\n",
    "            'wildlife_objects': wildlife_detections,\n",
    "            'animal_tags': sorted(animal_tags, key=lambda x: x['confidence'], reverse=True)[:5]\n",
    "        }\n",
    "    \n",
    "    return analyze_wildlife_image\n",
    "\n",
    "# Initialize Computer Vision demo\n",
    "cv_demo = demo_with_computer_vision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cv_demo_results(image_url):\n",
    "    \"\"\"Display Computer Vision analysis results\"\"\"\n",
    "    \n",
    "    print(\"ðŸ” Analyzing image with Azure Computer Vision...\")\n",
    "    result = cv_demo(image_url)\n",
    "    \n",
    "    # Display image\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Camera Trap Image')\n",
    "    \n",
    "    # Display results\n",
    "    plt.subplot(1, 2, 2)\n",
    "    if result['animal_tags']:\n",
    "        tags = [tag['name'] for tag in result['animal_tags'][:5]]\n",
    "        confidences = [tag['confidence'] for tag in result['animal_tags'][:5]]\n",
    "        \n",
    "        plt.barh(tags, confidences, color='steelblue')\n",
    "        plt.xlabel('Confidence Score')\n",
    "        plt.title('Animal Detection Tags')\n",
    "        plt.xlim(0, 1)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No animals detected', ha='center', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"ðŸ“ Description: {result['description']}\")\n",
    "    print(f\"ðŸ¦Œ Wildlife Objects: {len(result['wildlife_objects'])}\")\n",
    "    print(f\"ðŸ·ï¸ Animal Tags: {[tag['name'] for tag in result['animal_tags'][:3]]}\")\n",
    "\n",
    "# Demo with sample wildlife image\n",
    "sample_url = \"https://example.com/wildlife_image.jpg\"  # Replace with actual wildlife image URL\n",
    "# display_cv_demo_results(sample_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option B: Train Custom Vision Model (Real Implementation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_training_images_from_urls(project_id, tags, image_data):\n",
    "    \"\"\"\n",
    "    Upload training images from URLs to Custom Vision\n",
    "    \n",
    "    Args:\n",
    "        project_id: Custom Vision project ID\n",
    "        tags: Dictionary of tag objects\n",
    "        image_data: Dictionary with format {tag_name: [list_of_image_urls]}\n",
    "    \"\"\"\n",
    "    \n",
    "    for tag_name, image_urls in image_data.items():\n",
    "        if tag_name not in tags:\n",
    "            print(f\"âš ï¸ Skipping unknown tag: {tag_name}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"ðŸ“¤ Uploading {len(image_urls)} images for '{tag_name}'...\")\n",
    "        \n",
    "        # Process in batches (Custom Vision API limit: 64 images per batch)\n",
    "        batch_size = 10\n",
    "        for i in range(0, len(image_urls), batch_size):\n",
    "            batch_urls = image_urls[i:i+batch_size]\n",
    "            \n",
    "            image_list = []\n",
    "            for url in batch_urls:\n",
    "                try:\n",
    "                    image_list.append(ImageFileCreateEntry(\n",
    "                        name=f\"{tag_name}_{len(image_list)}.jpg\",\n",
    "                        contents=requests.get(url).content,\n",
    "                        tag_ids=[tags[tag_name].id]\n",
    "                    ))\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Failed to download {url}: {e}\")\n",
    "            \n",
    "            if image_list:\n",
    "                try:\n",
    "                    upload_result = trainer.create_images_from_files(\n",
    "                        project_id, ImageFileCreateBatch(images=image_list)\n",
    "                    )\n",
    "                    \n",
    "                    if upload_result.is_batch_successful:\n",
    "                        print(f\"âœ… Uploaded batch {i//batch_size + 1} for {tag_name}\")\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ Some images failed for {tag_name}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Upload failed for {tag_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data (replace with real wildlife image URLs)\n",
    "training_data = {\n",
    "    \"deer\": [\n",
    "        \"https://example.com/deer1.jpg\",\n",
    "        \"https://example.com/deer2.jpg\",\n",
    "        # Add 3-8 more deer images\n",
    "    ],\n",
    "    \"fox\": [\n",
    "        \"https://example.com/fox1.jpg\", \n",
    "        \"https://example.com/fox2.jpg\",\n",
    "        # Add 3-8 more fox images\n",
    "    ],\n",
    "    \"empty\": [\n",
    "        \"https://example.com/empty1.jpg\",\n",
    "        \"https://example.com/empty2.jpg\",\n",
    "        # Add 3-8 more empty camera trap images\n",
    "    ]\n",
    "}\n",
    "\n",
    "def train_custom_vision_model(project_id):\n",
    "    \"\"\"Train the Custom Vision model\"\"\"\n",
    "    \n",
    "    print(\"ðŸš€ Starting model training...\")\n",
    "    iteration = trainer.train_project(project_id)\n",
    "    \n",
    "    # Wait for training to complete\n",
    "    while iteration.status != \"Completed\":\n",
    "        iteration = trainer.get_iteration(project_id, iteration.id)\n",
    "        print(f\"â³ Training status: {iteration.status}\")\n",
    "        time.sleep(10)\n",
    "    \n",
    "    print(\"âœ… Training completed!\")\n",
    "    \n",
    "    # Publish the iteration\n",
    "    publish_iteration_name = \"wildlifeClassifier\"\n",
    "    trainer.publish_iteration(project_id, iteration.id, publish_iteration_name, PREDICTION_RESOURCE_ID)\n",
    "    print(f\"ðŸ“¦ Model published as: {publish_iteration_name}\")\n",
    "    \n",
    "    return iteration, publish_iteration_name\n",
    "\n",
    "# Upload training data and train model\n",
    "# upload_training_images_from_urls(project.id, tags, training_data)\n",
    "# iteration, model_name = train_custom_vision_model(project.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Custom Vision for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_wildlife_custom_vision(image_source, project_id, model_name=\"wildlifeClassifier\"):\n",
    "    \"\"\"\n",
    "    Classify wildlife using trained Custom Vision model\n",
    "    \n",
    "    Args:\n",
    "        image_source: Image URL or file path\n",
    "        project_id: Custom Vision project ID  \n",
    "        model_name: Published model name\n",
    "    \n",
    "    Returns:\n",
    "        Classification results\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load image\n",
    "    if image_source.startswith('http'):\n",
    "        image_data = requests.get(image_source).content\n",
    "    else:\n",
    "        with open(image_source, 'rb') as f:\n",
    "            image_data = f.read()\n",
    "    \n",
    "    # Make prediction\n",
    "    try:\n",
    "        results = predictor.classify_image(project_id, model_name, image_data)\n",
    "        \n",
    "        predictions = []\n",
    "        for prediction in results.predictions:\n",
    "            predictions.append({\n",
    "                'species': prediction.tag_name,\n",
    "                'confidence': round(prediction.probability, 3),\n",
    "                'percentage': f\"{prediction.probability * 100:.1f}%\"\n",
    "            })\n",
    "        \n",
    "        # Sort by confidence\n",
    "        predictions = sorted(predictions, key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'image_source': image_source,\n",
    "            'predictions': predictions,\n",
    "            'top_prediction': predictions[0] if predictions else None,\n",
    "            'high_confidence': predictions[0]['confidence'] > 0.7 if predictions else False\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Prediction error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_custom_vision_results(image_source, result):\n",
    "    \"\"\"Display Custom Vision classification results\"\"\"\n",
    "    \n",
    "    if not result:\n",
    "        print(\"âŒ No results to display\")\n",
    "        return\n",
    "    \n",
    "    # Load image\n",
    "    if image_source.startswith('http'):\n",
    "        response = requests.get(image_source)\n",
    "        img = Image.open(io.BytesIO(response.content))\n",
    "    else:\n",
    "        img = Image.open(image_source)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Show image\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Camera Trap Image', fontsize=14)\n",
    "    \n",
    "    # Show predictions\n",
    "    if result['predictions']:\n",
    "        species = [p['species'].replace('_', ' ').title() for p in result['predictions'][:5]]\n",
    "        confidences = [p['confidence'] for p in result['predictions'][:5]]\n",
    "        \n",
    "        bars = axes[1].barh(range(len(species)), confidences, color='forestgreen')\n",
    "        axes[1].set_yticks(range(len(species)))\n",
    "        axes[1].set_yticklabels(species)\n",
    "        axes[1].set_xlabel('Confidence Score')\n",
    "        axes[1].set_title('Species Predictions')\n",
    "        axes[1].set_xlim(0, 1)\n",
    "        \n",
    "        # Add confidence values\n",
    "        for i, (bar, conf) in enumerate(zip(bars, confidences)):\n",
    "            axes[1].text(conf + 0.01, i, f'{conf:.3f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    if result['top_prediction']:\n",
    "        top = result['top_prediction']\n",
    "        confidence_level = \"High\" if top['confidence'] > 0.7 else \"Medium\" if top['confidence'] > 0.4 else \"Low\"\n",
    "        print(f\"ðŸŽ¯ Best Match: {top['species'].replace('_', ' ').title()} ({top['percentage']}) - {confidence_level} Confidence\")\n",
    "\n",
    "# Example usage (after model is trained and published)\n",
    "# result = classify_wildlife_custom_vision(\"test_image.jpg\", project.id, \"wildlifeClassifier\")\n",
    "# display_custom_vision_results(\"test_image.jpg\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Processing for Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_with_custom_vision(image_list, project_id, model_name, survey_name=\"Wildlife Survey\"):\n",
    "    \"\"\"Process multiple images with Custom Vision for research analysis\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"ðŸ” Processing {len(image_list)} images with Custom Vision...\")\n",
    "    \n",
    "    for i, image_path in enumerate(image_list):\n",
    "        print(f\"Processing {i+1}/{len(image_list)}: {image_path.split('/')[-1]}\")\n",
    "        \n",
    "        result = classify_wildlife_custom_vision(image_path, project_id, model_name)\n",
    "        \n",
    "        if result and result['predictions']:\n",
    "            top_prediction = result['top_prediction']\n",
    "            results.append({\n",
    "                'image': image_path.split('/')[-1],\n",
    "                'species': top_prediction['species'],\n",
    "                'confidence': top_prediction['confidence'],\n",
    "                'high_confidence': result['high_confidence'],\n",
    "                'model_used': 'Azure Custom Vision'\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                'image': image_path.split('/')[-1],\n",
    "                'species': 'unknown',\n",
    "                'confidence': 0.0,\n",
    "                'high_confidence': False,\n",
    "                'model_used': 'Azure Custom Vision'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Example batch processing\n",
    "# image_paths = [\"image1.jpg\", \"image2.jpg\", \"image3.jpg\"]\n",
    "# batch_results = batch_process_with_custom_vision(image_paths, project.id, \"wildlifeClassifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Analysis Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_custom_vision_survey(results_df):\n",
    "    \"\"\"Generate research insights from Custom Vision results\"\"\"\n",
    "    \n",
    "    # Filter wildlife detections\n",
    "    wildlife_df = results_df[results_df['species'] != 'unknown']\n",
    "    \n",
    "    print(\"=== Custom Vision Wildlife Survey Analysis ===\")\n",
    "    print(f\"ðŸ“· Total Images Processed: {len(results_df)}\")\n",
    "    print(f\"ðŸ¦Œ Wildlife Detected: {len(wildlife_df)} ({len(wildlife_df)/len(results_df)*100:.1f}%)\")\n",
    "    print(f\"âœ… High-Confidence Detections: {len(wildlife_df[wildlife_df['high_confidence']])} ({len(wildlife_df[wildlife_df['high_confidence']])/len(results_df)*100:.1f}%)\")\n",
    "    \n",
    "    if len(wildlife_df) > 0:\n",
    "        species_counts = wildlife_df['species'].value_counts()\n",
    "        print(f\"\\nðŸ¥‡ Most Common Species: {species_counts.index[0]} ({species_counts.iloc[0]} detections)\")\n",
    "        print(f\"ðŸ“Š Species Diversity: {len(species_counts)} different species\")\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Species distribution\n",
    "        species_counts.head(6).plot(kind='bar', ax=axes[0,0], color='steelblue')\n",
    "        axes[0,0].set_title('Species Detection Frequency')\n",
    "        axes[0,0].set_ylabel('Number of Detections')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Confidence distribution\n",
    "        axes[0,1].hist(wildlife_df['confidence'], bins=15, alpha=0.7, color='forestgreen')\n",
    "        axes[0,1].set_title('Confidence Score Distribution')\n",
    "        axes[0,1].set_xlabel('Confidence Score')\n",
    "        axes[0,1].axvline(0.7, color='red', linestyle='--', label='High Confidence Threshold')\n",
    "        axes[0,1].legend()\n",
    "        \n",
    "        # Detection success by confidence threshold\n",
    "        thresholds = [0.3, 0.5, 0.7, 0.9]\n",
    "        success_rates = [len(wildlife_df[wildlife_df['confidence'] >= t]) / len(results_df) for t in thresholds]\n",
    "        \n",
    "        axes[1,0].plot(thresholds, success_rates, 'o-', color='orange', linewidth=2)\n",
    "        axes[1,0].set_title('Detection Rate by Confidence Threshold')\n",
    "        axes[1,0].set_xlabel('Confidence Threshold')\n",
    "        axes[1,0].set_ylabel('Detection Rate')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Model performance summary\n",
    "        high_conf_rate = len(wildlife_df[wildlife_df['high_confidence']]) / len(results_df) * 100\n",
    "        detection_rate = len(wildlife_df) / len(results_df) * 100\n",
    "        \n",
    "        metrics = ['Detection Rate', 'High Confidence Rate', 'Species Diversity Score']\n",
    "        values = [detection_rate, high_conf_rate, len(species_counts) / len(wildlife_df) * 100]\n",
    "        \n",
    "        axes[1,1].bar(metrics, values, color=['lightblue', 'lightgreen', 'lightyellow'])\n",
    "        axes[1,1].set_title('Model Performance Metrics')\n",
    "        axes[1,1].set_ylabel('Percentage / Score')\n",
    "        axes[1,1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'total_images': len(results_df),\n",
    "        'wildlife_detected': len(wildlife_df),\n",
    "        'detection_rate': len(wildlife_df) / len(results_df),\n",
    "        'high_confidence_rate': len(wildlife_df[wildlife_df['high_confidence']]) / len(results_df),\n",
    "        'species_diversity': len(wildlife_df['species'].unique()) if len(wildlife_df) > 0 else 0\n",
    "    }\n",
    "\n",
    "# Example analysis\n",
    "# survey_stats = analyze_custom_vision_survey(batch_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_custom_vision_results(results_df, project_name=\"wildlife_study\"):\n",
    "    \"\"\"Export Custom Vision results for research analysis\"\"\"\n",
    "    \n",
    "    # Main results CSV\n",
    "    results_df.to_csv(f\"{project_name}_custom_vision_results.csv\", index=False)\n",
    "    \n",
    "    # High-confidence detections for reliable research\n",
    "    reliable_df = results_df[results_df['high_confidence'] == True]\n",
    "    reliable_df.to_csv(f\"{project_name}_reliable_detections.csv\", index=False)\n",
    "    \n",
    "    # Species summary for ecological analysis\n",
    "    wildlife_df = results_df[results_df['species'] != 'unknown']\n",
    "    if len(wildlife_df) > 0:\n",
    "        species_summary = wildlife_df.groupby('species').agg({\n",
    "            'confidence': ['count', 'mean', 'std', 'min', 'max'],\n",
    "            'high_confidence': 'sum'\n",
    "        }).round(4)\n",
    "        \n",
    "        species_summary.to_csv(f\"{project_name}_species_analysis.csv\")\n",
    "    \n",
    "    print(f\"âœ… Custom Vision results exported:\")\n",
    "    print(f\"   â€¢ {project_name}_custom_vision_results.csv\")\n",
    "    print(f\"   â€¢ {project_name}_reliable_detections.csv\") \n",
    "    print(f\"   â€¢ {project_name}_species_analysis.csv\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Ready for R/Python statistical analysis!\")\n",
    "\n",
    "# Example export\n",
    "# export_custom_vision_results(batch_results, \"my_ecological_study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microsoft Custom Vision Advantages for Research\n",
    "\n",
    "### Why Choose Custom Vision:\n",
    "1. **No Coding Required**: Visual training interface in portal\n",
    "2. **Small Data Friendly**: Works with 5-10 images per species\n",
    "3. **Fast Training**: Model trains in 2-10 minutes\n",
    "4. **Research APIs**: Confidence scores, batch processing\n",
    "5. **Azure Integration**: Connects with other Microsoft AI services\n",
    "6. **Scalable**: Free tier â†’ enterprise depending on research needs\n",
    "\n",
    "### Research Workflow:\n",
    "1. **Collect sample images** (5-10 per species minimum)\n",
    "2. **Upload & tag** via Custom Vision portal\n",
    "3. **Train model** (automatic, takes ~5 minutes)\n",
    "4. **Test & iterate** with more training data\n",
    "5. **Deploy via API** for batch processing\n",
    "6. **Export results** for statistical analysis\n",
    "\n",
    "This approach transforms wildlife monitoring from manual review to automated classification, enabling researchers to process camera trap surveys at scale while maintaining scientific rigor through confidence-based validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
